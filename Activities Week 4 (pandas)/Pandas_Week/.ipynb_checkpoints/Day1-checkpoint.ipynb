{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Week Day 1 All Activities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructor Turn Activity 1: Jupyter Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ====================================\n",
    "# Activity 1 Instructor\n",
    "# Running the basic \"Hello World\" code\n",
    "# ====================================\n",
    "hello = \"Hello World\"\n",
    "print(hello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Doing simple math\n",
    "4 + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Storing results in variable \n",
    "a = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Using those variables elsewhere in the code\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Variables will hold the values most recently run\n",
    "# This means that, if we run the code above, it will now print 2\n",
    "a = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Students Turn Activity 2: Netflix Remix\n",
    "\n",
    "## Instructions\n",
    "\n",
    "  * Using `Netflix.py` as a jumping off point, convert the application so that it runs properly within a Jupyter Notebook.\n",
    "\n",
    "  * Make sure to have the application print out the user's input, the path to `Netflix_Ratings.csv`, and the final rating/review for the film in different cells.\n",
    "\n",
    "## Bonus\n",
    "\n",
    "  * Go through any of the activities from last week and attempt to convert them to run within a Jupyter Notebook. While doing this, try to split up the code into cells and print out the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ====================================\n",
    "# Activity 2 Student\n",
    "# ====================================\n",
    "# Code Here\n",
    "#Modules \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prompt user for video lookup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set path for file\n",
    "\n",
    "\n",
    "# Set variable to check if we found the video\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructor Turn Activity 3: Creating Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dependencies importing pandas and storing it to a variable called pd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Then create a Pandas Series from a raw list\n",
    "data_series = pd.Series([\"UC Irvine\", \"UCLA\", \"UC Berkley\", \"UC Riverside\", \"UC Davis\"])\n",
    "data_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert a list of dictionarys into a dataframe\n",
    "states_dicts = [{\"STATE\": \"California\", \"ABBREVIATION\" : \"CA\"},\n",
    "                {\"STATE\": \"New York\", \"ABBREVIATION\": \"NY\"}]\n",
    "dataframe_states = pd.DataFrame(states_dicts)\n",
    "dataframe_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert a single dictionary containing list into dataframe\n",
    "dataframe = pd.DataFrame(\n",
    "    {\n",
    "        \"Dynasty\": [\"Early Dynastic Period\", \"Old Kingdom\"],\n",
    "        \"Pharoh\": [\"Thinis\", \"Memphis\"]\n",
    "    }\n",
    ")\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Students Turn Activity 4: Data-Frame Shop\n",
    "\n",
    "## Instructions\n",
    "\n",
    "  * Create a DataFrame for a frame shop that contains three columns - \"Frame\", \"Price\", and \"Sales\" - and has five rows of data stored within it.\n",
    "\n",
    "  * Using an alternate method from that used before, create a DataFrame for an art gallery that contains three columns - \"Painting\", \"Price\", and \"Popularity\" - and has four rows of data stored within it.\n",
    "\n",
    "## Bonus\n",
    "\n",
    "  * Once both of the DataFrames have been created, discuss with those around you which method you prefer to use and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# DataFrame should have 3 columns: Frame, Price, and Sales AND 5 rows of data# DataF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use a different method of creating DataFrames to\n",
    "# Create a DataFrame for an art gallery that contains three columns - \"Painting\", \"Price\", and \"Popularity\"\n",
    "# and has 4 rows of data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructor Turn Activity 5: Data-Frame Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save path to data set in a variable\n",
    "data_file = os.path.join(\"Resources\", \"dataSet.csv\")\n",
    "print(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use Pandas to read data\n",
    "data_file_pd = pd.read_csv(data_file)\n",
    "data_file_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dislay a statistical overview of the DataFrame\n",
    "data_file_pd.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reference a single column within a DataFrame\n",
    "data_file_pd[\"Amount\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reference multiple columns within a DataFrame \n",
    "data_file_pd[[\"Amount\", \"Gender\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The mean method averages the series\n",
    "average = data_file_pd[\"Amount\"].mean()\n",
    "average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The sum method adds every entry in the series\n",
    "total = data_file_pd[\"Amount\"].sum()\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The unique method shows every element of the series that appears only once\n",
    "unique = data_file_pd[\"Last Name\"].unique()\n",
    "unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The value_counts method counts unique values in a column\n",
    "count = data_file_pd[\"Gender\"].value_counts()\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculations can also be performed on Series and added into DataFrames as new columns\n",
    "thousands_of_dollars = data_file_pd[\"Amount\"]/1000\n",
    "data_file_pd[\"Thousands of Dollars\"] = thousands_of_dollars\n",
    "\n",
    "data_file_pd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Students Turn: Activity 6 Training Grounds\n",
    "\n",
    "## Instructions\n",
    "\n",
    "  * Using the DataFrame provided, perform all of the following actions...\n",
    "\n",
    "  * Provide a simple, analytical overview of the dataset's numeric columns\n",
    "\n",
    "  * Collect all of the names of the trainers within the dataset\n",
    "\n",
    "  * Figure out how many students each trainer has\n",
    "\n",
    "  * Find the average weight of the students at the gym\n",
    "\n",
    "  * Find the combined weight of all of the students at the gym\n",
    "\n",
    "  * Convert the \"Membership (Days)\" column into weeks and then add this new series into the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ====================================\n",
    "# Activity 6 Student\n",
    "# ====================================\n",
    "# Import Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A gigantic DataFrame of individuals' names, their trainers, their weight, and their days as gym members\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Collecting a summary of all numeric data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Finding the names of the trainers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Finding how many students each trainer has\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Finding the average weight of all students\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Finding the combined weight of all students\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Converting the membership days into weeks and then adding a column to the DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructor Turn: Activity 7 Column Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A gigantic DataFrame of individuals' names, their trainers, their weight, and their days as gym members\n",
    "training_data = pd.DataFrame({\n",
    "    \"Name\":[\"Gino Walker\",\"Hiedi Wasser\",\"Kerrie Wetzel\",\"Elizabeth Sackett\",\"Jack Mitten\",\"Madalene Wayman\",\"Jamee Horvath\",\"Arlena Reddin\",\"Tula Levan\",\"Teisha Dreier\",\"Leslie Carrier\",\"Arlette Hartson\",\"Romana Merkle\",\"Heath Viviani\",\"Andres Zimmer\",\"Allyson Osman\",\"Yadira Caggiano\",\"Jeanmarie Friedrichs\",\"Leann Ussery\",\"Bee Mom\",\"Pandora Charland\",\"Karena Wooten\",\"Elizabet Albanese\",\"Augusta Borjas\",\"Erma Yadon\",\"Belia Lenser\",\"Karmen Sancho\",\"Edison Mannion\",\"Sonja Hornsby\",\"Morgan Frei\",\"Florencio Murphy\",\"Christoper Hertel\",\"Thalia Stepney\",\"Tarah Argento\",\"Nicol Canfield\",\"Pok Moretti\",\"Barbera Stallings\",\"Muoi Kelso\",\"Cicely Ritz\",\"Sid Demelo\",\"Eura Langan\",\"Vanita An\",\"Frieda Fuhr\",\"Ernest Fitzhenry\",\"Ashlyn Tash\",\"Melodi Mclendon\",\"Rochell Leblanc\",\"Jacqui Reasons\",\"Freeda Mccroy\",\"Vanna Runk\",\"Florinda Milot\",\"Cierra Lecompte\",\"Nancey Kysar\",\"Latasha Dalton\",\"Charlyn Rinaldi\",\"Erline Averett\",\"Mariko Hillary\",\"Rosalyn Trigg\",\"Sherwood Brauer\",\"Hortencia Olesen\",\"Delana Kohut\",\"Geoffrey Mcdade\",\"Iona Delancey\",\"Donnie Read\",\"Cesar Bhatia\",\"Evia Slate\",\"Kaye Hugo\",\"Denise Vento\",\"Lang Kittle\",\"Sherry Whittenberg\",\"Jodi Bracero\",\"Tamera Linneman\",\"Katheryn Koelling\",\"Tonia Shorty\",\"Misha Baxley\",\"Lisbeth Goering\",\"Merle Ladwig\",\"Tammie Omar\",\"Jesusa Avilla\",\"Alda Zabala\",\"Junita Dogan\",\"Jessia Anglin\",\"Peggie Scranton\",\"Dania Clodfelter\",\"Janis Mccarthy\",\"Edmund Galusha\",\"Tonisha Posey\",\"Arvilla Medley\",\"Briana Barbour\",\"Delfina Kiger\",\"Nia Lenig\",\"Ricarda Bulow\",\"Odell Carson\",\"Nydia Clonts\",\"Andree Resendez\",\"Daniela Puma\",\"Sherill Paavola\",\"Gilbert Bloomquist\",\"Shanon Mach\",\"Justin Bangert\",\"Arden Hokanson\",\"Evelyne Bridge\",\"Hee Simek\",\"Ward Deangelis\",\"Jodie Childs\",\"Janis Boehme\",\"Beaulah Glowacki\",\"Denver Stoneham\",\"Tarra Vinton\",\"Deborah Hummell\",\"Ulysses Neil\",\"Kathryn Marques\",\"Rosanna Dake\",\"Gavin Wheat\",\"Tameka Stoke\",\"Janella Clear\",\"Kaye Ciriaco\",\"Suk Bloxham\",\"Gracia Whaley\",\"Philomena Hemingway\",\"Claudette Vaillancourt\",\"Olevia Piche\",\"Trey Chiles\",\"Idalia Scardina\",\"Jenine Tremble\",\"Herbert Krider\",\"Alycia Schrock\",\"Miss Weibel\",\"Pearlene Neidert\",\"Kina Callender\",\"Charlotte Skelley\",\"Theodora Harrigan\",\"Sydney Shreffler\",\"Annamae Trinidad\",\"Tobi Mumme\",\"Rosia Elliot\",\"Debbra Putt\",\"Rena Delosantos\",\"Genna Grennan\",\"Nieves Huf\",\"Berry Lugo\",\"Ayana Verdugo\",\"Joaquin Mazzei\",\"Doris Harmon\",\"Patience Poss\",\"Magaret Zabel\",\"Marylynn Hinojos\",\"Earlene Marcantel\",\"Yuki Evensen\",\"Rema Gay\",\"Delana Haak\",\"Patricia Fetters\",\"Vinnie Elrod\",\"Octavia Bellew\",\"Burma Revard\",\"Lakenya Kato\",\"Vinita Buchner\",\"Sierra Margulies\",\"Shae Funderburg\",\"Jenae Groleau\",\"Louetta Howie\",\"Astrid Duffer\",\"Caron Altizer\",\"Kymberly Amavisca\",\"Mohammad Diedrich\",\"Thora Wrinkle\",\"Bethel Wiemann\",\"Patria Millet\",\"Eldridge Burbach\",\"Alyson Eddie\",\"Zula Hanna\",\"Devin Goodwin\",\"Felipa Kirkwood\",\"Kurtis Kempf\",\"Kasey Lenart\",\"Deena Blankenship\",\"Kandra Wargo\",\"Sherrie Cieslak\",\"Ron Atha\",\"Reggie Barreiro\",\"Daria Saulter\",\"Tandra Eastman\",\"Donnell Lucious\",\"Talisha Rosner\",\"Emiko Bergh\",\"Terresa Launius\",\"Margy Hoobler\",\"Marylou Stelling\",\"Lavonne Justice\",\"Kala Langstaff\",\"China Truett\",\"Louanne Dussault\",\"Thomasena Samaniego\",\"Charlesetta Tarbell\",\"Fatimah Lade\",\"Malisa Cantero\",\"Florencia Litten\",\"Francina Fraise\",\"Patsy London\",\"Deloris Mclaughlin\"],\n",
    "    \"Trainer\":['Bettyann Savory','Mariah Barberio','Gordon Perrine','Pa Dargan','Blanch Victoria','Aldo Byler','Aldo Byler','Williams Camire','Junie Ritenour','Gordon Perrine','Bettyann Savory','Mariah Barberio','Aldo Byler','Barton Stecklein','Bettyann Savory','Barton Stecklein','Gordon Perrine','Pa Dargan','Aldo Byler','Brittani Brin','Bettyann Savory','Phyliss Houk','Bettyann Savory','Junie Ritenour','Aldo Byler','Calvin North','Brittani Brin','Junie Ritenour','Blanch Victoria','Brittani Brin','Bettyann Savory','Blanch Victoria','Mariah Barberio','Bettyann Savory','Blanch Victoria','Brittani Brin','Junie Ritenour','Pa Dargan','Gordon Perrine','Phyliss Houk','Pa Dargan','Mariah Barberio','Phyliss Houk','Phyliss Houk','Calvin North','Williams Camire','Brittani Brin','Gordon Perrine','Bettyann Savory','Bettyann Savory','Pa Dargan','Phyliss Houk','Barton Stecklein','Blanch Victoria','Coleman Dunmire','Phyliss Houk','Blanch Victoria','Pa Dargan','Harland Coolidge','Calvin North','Bettyann Savory','Phyliss Houk','Bettyann Savory','Harland Coolidge','Gordon Perrine','Junie Ritenour','Harland Coolidge','Blanch Victoria','Mariah Barberio','Coleman Dunmire','Aldo Byler','Bettyann Savory','Gordon Perrine','Bettyann Savory','Barton Stecklein','Harland Coolidge','Aldo Byler','Aldo Byler','Pa Dargan','Junie Ritenour','Brittani Brin','Junie Ritenour','Gordon Perrine','Mariah Barberio','Mariah Barberio','Mariah Barberio','Bettyann Savory','Brittani Brin','Aldo Byler','Phyliss Houk','Blanch Victoria','Pa Dargan','Phyliss Houk','Brittani Brin','Barton Stecklein','Coleman Dunmire','Bettyann Savory','Bettyann Savory','Gordon Perrine','Blanch Victoria','Junie Ritenour','Phyliss Houk','Coleman Dunmire','Williams Camire','Harland Coolidge','Williams Camire','Aldo Byler','Harland Coolidge','Gordon Perrine','Brittani Brin','Coleman Dunmire','Calvin North','Phyliss Houk','Brittani Brin','Aldo Byler','Bettyann Savory','Brittani Brin','Gordon Perrine','Calvin North','Harland Coolidge','Coleman Dunmire','Harland Coolidge','Aldo Byler','Junie Ritenour','Blanch Victoria','Harland Coolidge','Blanch Victoria','Junie Ritenour','Harland Coolidge','Junie Ritenour','Gordon Perrine','Brittani Brin','Coleman Dunmire','Williams Camire','Junie Ritenour','Brittani Brin','Calvin North','Barton Stecklein','Barton Stecklein','Mariah Barberio','Coleman Dunmire','Bettyann Savory','Mariah Barberio','Pa Dargan','Barton Stecklein','Coleman Dunmire','Brittani Brin','Barton Stecklein','Pa Dargan','Barton Stecklein','Junie Ritenour','Bettyann Savory','Williams Camire','Pa Dargan','Calvin North','Williams Camire','Coleman Dunmire','Aldo Byler','Barton Stecklein','Coleman Dunmire','Blanch Victoria','Mariah Barberio','Mariah Barberio','Harland Coolidge','Barton Stecklein','Phyliss Houk','Pa Dargan','Bettyann Savory','Barton Stecklein','Harland Coolidge','Junie Ritenour','Pa Dargan','Mariah Barberio','Blanch Victoria','Williams Camire','Phyliss Houk','Phyliss Houk','Coleman Dunmire','Mariah Barberio','Gordon Perrine','Coleman Dunmire','Brittani Brin','Pa Dargan','Coleman Dunmire','Brittani Brin','Blanch Victoria','Coleman Dunmire','Gordon Perrine','Coleman Dunmire','Aldo Byler','Aldo Byler','Mariah Barberio','Williams Camire','Phyliss Houk','Aldo Byler','Williams Camire','Aldo Byler','Williams Camire','Coleman Dunmire','Phyliss Houk'],\n",
    "    \"Weight\":[128,180,193,177,237,166,224,208,177,241,114,161,162,151,220,142,193,193,124,130,132,141,190,239,213,131,172,127,184,157,215,122,181,240,218,205,239,217,234,158,180,131,194,171,177,110,117,114,217,123,248,189,198,127,182,121,224,111,151,170,188,150,137,231,222,186,139,175,178,246,150,154,129,216,144,198,228,183,173,129,157,199,186,232,172,157,246,239,214,161,132,208,187,224,164,177,175,224,219,235,112,241,243,179,208,196,131,207,182,233,191,162,173,197,190,182,231,196,196,143,250,174,138,135,164,204,235,192,114,179,215,127,185,213,250,213,153,217,176,190,119,167,118,208,113,206,200,236,159,218,168,159,156,183,121,203,215,209,179,219,174,220,129,188,217,250,166,157,112,236,182,144,189,243,238,147,165,115,160,134,245,174,238,157,150,184,174,134,134,248,199,165,117,119,162,112,170,224,247,217],\n",
    "    \"Membership(Days)\":[52,70,148,124,186,157,127,155,37,185,158,129,93,69,124,13,76,153,164,161,48,121,167,69,39,163,7,34,176,169,108,162,195,86,155,77,197,200,80,142,179,67,58,145,188,147,125,15,13,173,125,4,61,29,132,110,62,137,197,135,162,174,32,151,149,65,18,42,63,62,104,200,189,40,38,199,1,12,8,2,195,30,7,72,130,144,2,34,200,143,43,196,22,115,171,54,143,59,14,52,109,115,187,185,26,19,178,18,120,169,45,52,130,69,168,178,96,22,78,152,39,51,118,130,60,156,108,69,103,158,165,142,86,91,117,77,57,169,86,188,97,111,22,83,81,177,163,35,12,164,21,181,171,138,22,107,58,51,38,128,19,193,157,13,104,89,13,10,26,190,179,101,7,159,100,49,120,109,56,199,51,108,47,171,69,162,74,119,148,88,32,159,65,146,140,171,88,18,59,13]\n",
    "})\n",
    "training_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Collecting a list of all columns within the DataFrame\n",
    "training_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reorganizing the columns using double brackets\n",
    "organized_df = training_data[[\"Name\",\"Trainer\",\"Weight\",\"Membership(Days)\"]]\n",
    "organized_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using .rename(columns={}) in order to rename columns\n",
    "renamed_df = organized_df.rename(columns={\"Membership(Days)\":\"Membership in Days\", \"Weight\":\"Weight in Pounds\"})\n",
    "renamed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Students Turn:  Activity 8 Hey, Arnold!\n",
    "\n",
    "* This assignment will give you experience creating DataFrames from scratch.\n",
    "\n",
    "* You will create a pandas DataFrame of characters from this TV show: [https://en.wikipedia.org/wiki/Hey_Arnold!](https://en.wikipedia.org/wiki/Hey_Arnold!)\n",
    "\n",
    "## Instructions\n",
    "\n",
    "1. First, use Pandas to create a DataFrame with the following columns and values:\n",
    "\n",
    "* `Character_in_show`: Arnold, Gerald, Helga, Phoebe, Harold, Eugene\n",
    "\n",
    "* `color_of_hair`: blonde, black, blonde, black, unknown, red\n",
    "\n",
    "* `Height`: average, tallish, tallish, short, tall, short\n",
    "\n",
    "* `Football_Shaped_Head`: True, False, False, False, False, False\n",
    "\n",
    "2. You'll note that the above column names are inconsistent and difficult to work with. Rename them to the following, respectively:\n",
    "\n",
    "* `Character`, `Hair Color`, `Height`, `Football Head`\n",
    "\n",
    "3. Next, create a new table that contains all of the columns in the following order...\n",
    "\n",
    "* `Character`, `Football Head`, `Hair Color`, `Height`\n",
    "\n",
    "4. Finally, save the file in Excel format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a data frame with given columns and value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Rename columns to clean up the look \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Organize columns into a more logical order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Export new data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructor Turn: Activity 9  Reading and Writing CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store filepath in a variable\n",
    "file_one = \"Resources/DataOne.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read our Data file with the pandas library\n",
    "# Not every CSV requires an encoding, but be aware this can come up\n",
    "file_one_df = pd.read_csv(file_one, encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Show just the header\n",
    "file_one_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Show a single column\n",
    "file_one_df[\"first_name\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Show mulitple specific columns--note the extra brackets\n",
    "file_one_df[[\"first_name\", \"email\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Head does not change the DataFrame--it only displays it\n",
    "file_one_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Export file as a CSV, without the Pandas index, but with the header\n",
    "file_one_df.to_csv(\"Output/fileOne.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Students Turn Activity 10:  GoodReads - Part 1\n",
    "\n",
    "## Instructions\n",
    "\n",
    "  * Read in the GoodReads CSV using Pandas\n",
    "\n",
    "  * Remove unnecessary columns from the DataFrame so that only the following columns remain: `isbn`, `original_publication_year`, `original_title`, `authors`, `ratings_1`, `ratings_2`, `ratings_3`, `ratings_4`, and `ratings_5`\n",
    "\n",
    "  * Rename the columns to the following: `ISBN`, `Publication Year`, `Original Title`, `Authors`, `One Star Reviews`, `Two Star Reviews`, `Three Star Reviews`, `Four Star Reviews`, and `Five Star Reviews`\n",
    "\n",
    "  * Write the DataFrame into a new CSV file\n",
    "\n",
    "## Hints\n",
    "\n",
    "  * The base CSV file uses UTF-8 encoding. Trying to read in the file using some other kind of encoding could lead to strange characters appearing within the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make a reference to the books.csv file path\n",
    "\n",
    "# Import the books.csv file as a DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove unecessary columns from the DataFrame and save the new DataFrame\n",
    "# Only keep: \"isbn\", \"original_publication_year\", \"original_title\", \"authors\",\n",
    "# \"ratings_1\", \"ratings_2\", \"ratings_3\", \"ratings_4\", \"ratings_5\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Rename the headers to be more explanatory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Push the remade DataFrame to a new CSV file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Students Turn Activity 11: GoodReads - Part II\n",
    "\n",
    "## Instructions\n",
    "\n",
    "  * Using the modified DataFrame that was created earlier, create a summary table for the dataset that includes the following pieces of information...\n",
    "\n",
    "  * The count of unique authors within the DataFrame\n",
    "\n",
    "  * The year of the earliest published book in the DataFrame\n",
    "\n",
    "  * The year of the latest published book in the DataFrame\n",
    "\n",
    "  * The total number of reviews within the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# File to Load\n",
    "\n",
    "# Read the modified GoodReads csv and store into Pandas DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the number of unique authors in the DataFrame\n",
    "\n",
    "\n",
    "# Calculate the earliest/latest year a book was published\n",
    "\n",
    "\n",
    "# Calculate the total reviews for the entire dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Place all of the data found into a summary DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
